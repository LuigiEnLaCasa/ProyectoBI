# ğŸŒ Clasificador ODS - Objetivos de Desarrollo Sostenible

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto es una aplicaciÃ³n web completa para la **clasificaciÃ³n automÃ¡tica de textos** segÃºn los **17 Objetivos de Desarrollo Sostenible (ODS)** de las Naciones Unidas. La aplicaciÃ³n utiliza tÃ©cnicas de Machine Learning para identificar automÃ¡ticamente a quÃ© ODS pertenece un texto dado.

### ğŸ¯ Funcionalidades Principales

- **ğŸ”® PredicciÃ³n en tiempo real**: ClasificaciÃ³n de textos individuales o por lotes
- **ğŸ“Š AnÃ¡lisis avanzado**: MÃ©tricas, grÃ¡ficos y estadÃ­sticas de confianza
- **ğŸ”„ Re-entrenamiento**: Capacidad de mejorar el modelo con nuevos datos
- **âš™ï¸ GestiÃ³n de modelos**: AdministraciÃ³n de mÃºltiples versiones de modelos
- **ğŸ“ Carga de archivos**: Soporte para CSV y Excel
- **ğŸ¨ Interfaz intuitiva**: Dashboard web con Streamlit

---

## ğŸ—ï¸ Arquitectura del Sistema

```
ğŸ“¦ Proyecto1/
â”œâ”€â”€ ğŸš€ api/                    # Backend FastAPI
â”‚   â”œâ”€â”€ app.py                 # AplicaciÃ³n principal de la API
â”‚   â””â”€â”€ routes/                # Endpoints de la API
â”œâ”€â”€ ğŸ“Š data/                   # Datasets y archivos
â”‚   â”œâ”€â”€ train/                 # Datos de entrenamiento
â”‚   â””â”€â”€ test/                  # Datos de prueba
â”œâ”€â”€ ğŸ¤– models/                 # Modelos ML entrenados
â”œâ”€â”€ ğŸ’» src/                    # CÃ³digo fuente del ML
â”œâ”€â”€ ğŸŒ streamlit_app.py        # Frontend web
â””â”€â”€ ğŸ“„ requirements.txt        # Dependencias Python
```

### ğŸ”§ Componentes TÃ©cnicos

- **Backend**: FastAPI con endpoints REST
- **Frontend**: Streamlit para interfaz web
- **ML Pipeline**: scikit-learn con MultinomialNB
- **Procesamiento**: NLTK para procesamiento de lenguaje natural
- **VisualizaciÃ³n**: Plotly para grÃ¡ficos interactivos

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### ğŸ“‹ Prerrequisitos

- **Python 3.8+** (Recomendado: Python 3.10-3.11)
- **Git** (para clonar el repositorio)
- **pip** (gestor de paquetes de Python)

### 1ï¸âƒ£ Clonar el Repositorio

```bash
# Clonar desde GitHub
git clone https://github.com/LuigiEnLaCasa/ProyectoBI.git

# Navegar al directorio del proyecto
cd ProyectoBI/Proyecto1
```

### 2ï¸âƒ£ Crear Entorno Virtual (Recomendado)

```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# En Windows:
venv\Scripts\activate
# En Linux/Mac:
source venv/bin/activate
```

### 3ï¸âƒ£ Instalar Dependencias

```bash
# Instalar todas las dependencias
pip install -r requirements.txt

# Verificar instalaciÃ³n
pip list
```

### 4ï¸âƒ£ Configurar Datos Iniciales

Los datasets necesarios ya estÃ¡n incluidos en el repositorio:
- `data/train/DatosAumentadosTrain.xlsx` (2,376 ejemplos - Dataset principal)
- `data/train/Datos_etapa1.xlsx` (2,424 ejemplos - Dataset alternativo)

---

## â–¶ï¸ EjecuciÃ³n del Proyecto

### ğŸ”¥ MÃ©todo 1: EjecuciÃ³n AutomÃ¡tica (Recomendado)

```bash
# Ejecutar el script de inicio automÃ¡tico
./start_app.bat  # En Windows
```

O manualmente:

```bash
# 1. Iniciar el backend (Terminal 1)
cd api
uvicorn app:app --host 127.0.0.1 --port 8000 --reload

# 2. Iniciar el frontend (Terminal 2 - Nueva ventana)
streamlit run streamlit_app.py --server.port 8501
```

### ğŸŒ Acceder a la AplicaciÃ³n

Una vez iniciados ambos servicios:

- **ğŸŒŸ AplicaciÃ³n Web**: http://localhost:8501
- **ğŸ“¡ API Backend**: http://127.0.0.1:8000
- **ğŸ“– DocumentaciÃ³n API**: http://127.0.0.1:8000/docs

---

## ğŸ® GuÃ­a de Uso

### 1ï¸âƒ£ **PestaÃ±a PredicciÃ³n** ğŸ”®
- Ingresa texto manualmente o sube archivos CSV/Excel
- ObtÃ©n clasificaciones ODS con porcentajes de confianza
- Descarga resultados en formato CSV

### 2ï¸âƒ£ **PestaÃ±a Re-entrenamiento** ğŸ”„
- Selecciona dataset base (DatosAumentados por defecto)
- Carga nuevos ejemplos de entrenamiento
- Entrena modelo mejorado automÃ¡ticamente

### 3ï¸âƒ£ **PestaÃ±a AnÃ¡lisis** ğŸ“Š
- Visualiza mÃ©tricas de predicciones realizadas
- GrÃ¡ficos de distribuciÃ³n por ODS
- EstadÃ­sticas de confianza y rendimiento

### 4ï¸âƒ£ **PestaÃ±a GestiÃ³n** âš™ï¸
- Administra modelos disponibles
- Sube nuevos archivos de entrenamiento
- Actualiza lista de modelos

---

## ğŸ“ Archivos Importantes

### ğŸ“‹ **Archivos Esenciales (NO ELIMINAR)**

```
â”œâ”€â”€ streamlit_app.py           # â­ AplicaciÃ³n web principal
â”œâ”€â”€ api/app.py                 # â­ Backend FastAPI
â”œâ”€â”€ api/routes/                # â­ Endpoints de la API
â”œâ”€â”€ src/                       # â­ CÃ³digo ML y pipeline
â”œâ”€â”€ data/train/                # â­ Datasets de entrenamiento
â”œâ”€â”€ requirements.txt           # â­ Dependencias Python
â””â”€â”€ start_app.bat             # â­ Script de inicio automÃ¡tico
```

### ğŸ“Š **Datasets Incluidos**

- **DatosAumentadosTrain.xlsx**: Dataset principal (2,376 ejemplos)
- **Datos_etapa1.xlsx**: Dataset alternativo (2,424 ejemplos)
- Ambos incluyen columnas: `texto` y `ods` (1, 3, 4)

### ğŸ¤– **Modelos ML**

Los modelos se generan automÃ¡ticamente en `/models/` al entrenar:
- Formato: `modelo_ods_YYYYMMDD_HHMMSS.pkl`
- Incluyen pipeline completo (vectorizaciÃ³n + clasificador)

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### ğŸŒ **Configurar URLs de API**

Si necesitas cambiar las URLs por defecto:

```python
# En streamlit_app.py, lÃ­nea ~29
API_BASE_URL = "http://127.0.0.1:8000"  # Cambiar aquÃ­ si es necesario
```

### ğŸ¨ **Personalizar Puerto Streamlit**

```bash
streamlit run streamlit_app.py --server.port PUERTO_DESEADO
```

### ğŸ“Š **Agregar Nuevos Datasets**

1. Colocar archivo Excel/CSV en `data/train/`
2. Asegurar columnas: `texto` y `ods`
3. Valores ODS vÃ¡lidos: 1, 3, 4
4. Reiniciar aplicaciÃ³n para detectar nuevo dataset

---

## ğŸ› SoluciÃ³n de Problemas

### âŒ **Error: "No module named 'X'"**
```bash
pip install -r requirements.txt --force-reinstall
```

### âŒ **Error: "API no conectada"**
```bash
# Verificar que el backend estÃ© ejecutÃ¡ndose
curl http://127.0.0.1:8000/health
# O visitar en navegador: http://127.0.0.1:8000/docs
```

### âŒ **Error: "Puerto ocupado"**
```bash
# Cambiar puerto de Streamlit
streamlit run streamlit_app.py --server.port 8502

# O matar procesos
taskkill /f /im python.exe  # Windows
pkill -f streamlit          # Linux/Mac
```

### âŒ **Problemas con modelos**
```bash
# Limpiar cache de modelos
rm -rf models/*.pkl
# Entrenar nuevo modelo desde la aplicaciÃ³n web
```

---

## ğŸš¢ Despliegue en ProducciÃ³n

### ğŸ³ **Docker (Recomendado)**

```dockerfile
# Dockerfile ejemplo
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

# Exponer puertos
EXPOSE 8000 8501

# Script de inicio
CMD ["sh", "-c", "uvicorn api.app:app --host 0.0.0.0 --port 8000 & streamlit run streamlit_app.py --server.port 8501 --server.address 0.0.0.0"]
```

### â˜ï¸ **Servicios en la Nube**

- **Heroku**: Usar `Procfile` con gunicorn
- **AWS EC2**: Instalar nginx como proxy reverso
- **Google Cloud Run**: Containerizar con Docker
- **Azure Container Instances**: Deployment directo

---

## ğŸ‘¥ Equipo de Desarrollo

- **Desarrollador Principal**: Luis Alberto Pinilla
- **TecnologÃ­as**: Python, FastAPI, Streamlit, scikit-learn
- **Repositorio**: [GitHub - ProyectoBI](https://github.com/LuigiEnLaCasa/ProyectoBI)

---

## ğŸ“ Notas de VersiÃ³n

### v1.0.0 - Octubre 2025
- âœ… ClasificaciÃ³n automÃ¡tica ODS (1, 3, 4)
- âœ… Interfaz web completa con Streamlit
- âœ… API REST con FastAPI
- âœ… Re-entrenamiento dinÃ¡mico de modelos
- âœ… AnÃ¡lisis y visualizaciones avanzadas
- âœ… GestiÃ³n de mÃºltiples datasets
- âœ… ExportaciÃ³n de resultados CSV

---

## ğŸ†˜ Soporte y Contacto

Para reportar problemas o solicitar nuevas funcionalidades:

1. **Crear Issue**: En el repositorio de GitHub
2. **Email**: Contactar al desarrollador
3. **DocumentaciÃ³n**: Revisar `/docs/` para detalles tÃ©cnicos

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

---

**ğŸ‰ Â¡Listo para clasificar textos ODS! ğŸŒ**